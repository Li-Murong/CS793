{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:03:04.978620Z",
     "start_time": "2024-09-17T08:02:57.962921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    words = nltk.word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "    words = [word for word in words if word.isalpha()]  # Remove punctuation/numbers\n",
    "    return words\n",
    "\n",
    "\n",
    "# Compute word frequencies\n",
    "def get_word_frequencies(words):\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "# Create theoretical Zipf distribution\n",
    "def get_theoretical_zipf_distribution(num_words, s):\n",
    "    ranks = np.arange(1, num_words + 1)\n",
    "    theoretical_zipf = 1 / (ranks ** s)  # Theoretical Zipf distribution\n",
    "    theoretical_zipf /= np.sum(theoretical_zipf)  # Normalize to make it a probability distribution\n",
    "    return theoretical_zipf\n",
    "\n",
    "\n",
    "# Read and collect word frequencies from directory\n",
    "def read_and_collect_frequencies_from_directory(directory_path):\n",
    "    all_frequencies = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):  # Only read .txt files\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()  # Read the text file\n",
    "                words = preprocess_text(text)  # Preprocess the text (tokenize, lowercase, remove punctuation)\n",
    "                frequencies = get_word_frequencies(words)  # Get word frequencies\n",
    "                all_frequencies.append((filename, frequencies))  # Store file name and its frequencies\n",
    "    return all_frequencies\n",
    "\n",
    "\n",
    "def texts_selection(dict):\n",
    "    print('Choose texts to compare:')\n",
    "    for i, k in enumerate(dict.keys(), 1):\n",
    "        print(i, '.', k)\n",
    "    print('Select types:')\n",
    "    input_dir = input()\n",
    "\n",
    "\n",
    "# Get Q-Q Plot for each txt file, and set paremeter as 1.15\n",
    "def plot_qq_for_zipf_law(all_frequencies, s=1.15):\n",
    "    for filename, frequencies in all_frequencies:\n",
    "        # Step 1: Get the word frequencies sorted in descending order\n",
    "        word_counts = np.array([count for word, count in frequencies.most_common()])\n",
    "        num_words = len(word_counts)\n",
    "\n",
    "        # Step 2: Create the theoretical Zipf distribution\n",
    "        theoretical_zipf = get_theoretical_zipf_distribution(num_words, s)\n",
    "\n",
    "        # Step 3: Normalize word counts to make them a probability distribution\n",
    "        word_probabilities = word_counts / np.sum(word_counts)\n",
    "\n",
    "        # Step 4: Get Quantiles\n",
    "        zipf_quantile = np.cumsum(np.flip(theoretical_zipf))\n",
    "        word_quantile = np.cumsum(np.flip(word_probabilities))\n",
    "\n",
    "        # Step 4: Generate the QQ plot\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.scatter(zipf_quantile, word_quantile, alpha=0.6, label='Actual vs Theoretical')\n",
    "\n",
    "        # Plot a reference line (y=x) to visualize deviation from Zipf law\n",
    "        max_val = max(max(zipf_quantile), max(word_quantile))\n",
    "        plt.plot([0, max_val], [0, max_val], color='red', linestyle='--')\n",
    "\n",
    "        plt.title(f'QQ Plot for Zipf Law - {filename}')\n",
    "        plt.xlabel('Theoretical Quantiles (Zipf)')\n",
    "        plt.ylabel('Actual Quantiles (Word Frequencies)')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_qq_for_comparison(all_frequencies, s=1.15):\n",
    "    titles = []\n",
    "    probs = []\n",
    "    for filename, frequencies in all_frequencies:\n",
    "        # Step 1: Get the word frequencies sorted in descending order\n",
    "        word_counts = np.array([count for word, count in frequencies.most_common()])\n",
    "\n",
    "        # Step 2: Normalize word counts to make them a probability distribution\n",
    "        word_probabilities = word_counts / np.sum(word_counts)\n",
    "\n",
    "        titles.append(filename)\n",
    "        probs.append(word_probabilities)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(np.arange(1, len(probs[0]) + 1), probs[0], marker='.', alpha=0.6, label=f'{titles[0]}')\n",
    "\n",
    "    plt.scatter(np.arange(1, len(probs[1]) + 1), probs[1], marker='x', alpha=0.6, label=f'{titles[1]}')\n",
    "\n",
    "    plt.title(f'Distribution Plot for comparison: - {titles[0]} vs {titles[1]}')\n",
    "    plt.xlabel('Rank')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "categories = {\n",
    "    \"Finance\": 'finance',\n",
    "    \"Neural Net\": 'NN',\n",
    "    \"Aero Physics\": 'Physics',\n",
    "    \"President Inaugural Address\": 'speech',\n",
    "    \"Wikipedia\": 'Wiki'\n",
    "}\n",
    "\n",
    "\n",
    "def display_menu():\n",
    "    print(\"Types:\")\n",
    "    for index, (key, value) in enumerate(categories.items(), 1):\n",
    "        print(f\"{index}. {key}\")\n",
    "\n",
    "\n",
    "# 获取用户选择的数字，查找对应的目录地址\n",
    "def get_directory_choice():\n",
    "    choice = int(input(\"Select type: \"))\n",
    "    descriptions = list(categories.keys())\n",
    "    if 1 <= choice <= len(descriptions):\n",
    "        selected_description = descriptions[choice - 1]\n",
    "        selected_directory = categories[selected_description]\n",
    "        return selected_directory\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 列出该目录下的所有文件\n",
    "def list_files_in_directory(directory):\n",
    "    try:\n",
    "        files = os.listdir(directory)\n",
    "        print(f\"Texts in '{directory}' :\")\n",
    "        for index, file in enumerate(files, start=1):\n",
    "            print(f\"{index}. {file}\")\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(\"No Such File\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# 获取用户选择的文件\n",
    "def get_file_choice(files):\n",
    "    choice = int(input(\"Select file: \"))\n",
    "    if 1 <= choice <= len(files):\n",
    "        return files[choice - 1]\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 主程序逻辑\n",
    "all_frequencies = []\n",
    "for i in range(2):\n",
    "    display_menu()\n",
    "    directory = get_directory_choice()\n",
    "    if directory:\n",
    "        files = list_files_in_directory(directory)\n",
    "        if files:\n",
    "            selected_file = get_file_choice(files)\n",
    "            if selected_file:\n",
    "                print(f\"Selected file: {selected_file}\")\n",
    "                with open(os.path.join(directory, selected_file), 'r', encoding='utf-8') as file:\n",
    "                    text = file.read()  # Read the text file\n",
    "                    words = preprocess_text(text)  # Preprocess the text (tokenize, lowercase, remove punctuation)\n",
    "                    frequencies1 = get_word_frequencies(words)  # Get word frequencies\n",
    "                    all_frequencies.append((selected_file, frequencies1))\n",
    "            else:\n",
    "                print(\"No file\")\n",
    "        else:\n",
    "            print(\"Empty\")\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "\n",
    "plot_qq_for_comparison(all_frequencies)\n"
   ],
   "id": "9b1fa5b07621609",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types:\n",
      "1. Finance\n",
      "2. Neural Net\n",
      "3. Aero Physics\n",
      "4. President Inaugural Address\n",
      "5. Wikipedia\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 164\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m    163\u001B[0m     display_menu()\n\u001B[0;32m--> 164\u001B[0m     directory \u001B[38;5;241m=\u001B[39m \u001B[43mget_directory_choice\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m directory:\n\u001B[1;32m    166\u001B[0m         files \u001B[38;5;241m=\u001B[39m list_files_in_directory(directory)\n",
      "Cell \u001B[0;32mIn[1], line 126\u001B[0m, in \u001B[0;36mget_directory_choice\u001B[0;34m()\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_directory_choice\u001B[39m():\n\u001B[0;32m--> 126\u001B[0m     choice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSelect type: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m     descriptions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(categories\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m choice \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(descriptions):\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a9a877dce0d738a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
